
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    
    <title>PDE-constrained optimisation</title>
    
    <link rel="stylesheet" href="../_static/fenics.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    
    <script type="text/javascript">
      var DOCUMENTATION_OPTIONS = {
        URL_ROOT:    '../',
        VERSION:     '2017.1',
        COLLAPSE_INDEX: false,
        FILE_SUFFIX: '.html',
        HAS_SOURCE:  true,
        SOURCELINK_SUFFIX: '.txt'
      };
    </script>
    <script type="text/javascript" src="../_static/jquery.js"></script>
    <script type="text/javascript" src="../_static/underscore.js"></script>
    <script type="text/javascript" src="../_static/doctools.js"></script>
    <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
<!--[if lte IE 6]>
<link rel="stylesheet" href="../_static/ie6.css" type="text/css" media="screen" charset="utf-8" />
<![endif]-->

<link rel="stylesheet" href="../_static/featured.css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.5.1/jquery.min.js"></script>
<script src="../_static/slides.min.jquery.js"></script>
  <script>
	$(function(){
		$('#products').slides({
			preload: true,
			preloadImage: 'img/loading.gif',
			effect: 'slide, fade',
			crossfade: true,
			slideSpeed: 350,
			fadeSpeed: 500,
			generateNextPrev: false,
			generatePagination: false,
	                play: 5000,
                        hoverPause: false,
                        animationStart: function(current){
				$('.caption').animate({
					bottom:-35
				},100);
				if (window.console && console.log) {
					// example return of current slide number
					console.log('animationStart on slide: ', current);
				};
			},
			animationComplete: function(current){
				$('.caption').animate({
					bottom:0
				},200);
				if (window.console && console.log) {
					// example return of current slide number
					console.log('animationComplete on slide: ', current);
				};
			},
			slidesLoaded: function() {
				$('.caption').animate({
					bottom:0
				},200);
			}
		});
	});
  </script>
<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-31806773-1']);
  _gaq.push(['_setDomainName', 'dolfin-adjoint.org']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!-- Load the flex slider library -->
<link rel="stylesheet" href="_static/flexslider/flexslider.css" type="text/css">
<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.6.2/jquery.min.js"></script>
<script src="_static/flexslider/jquery.flexslider.js"></script>

<script type="text/javascript" charset="utf-8">
  $(window).load(function() {
  $('.flexslider').flexslider();
  });
</script>

<!-- Load the code highlight library -->
<link rel="stylesheet" href="_static/highlight/styles/zenburn.css">
<script src="_static/highlight/highlight.pack.js"></script>
<script>hljs.initHighlightingOnLoad();</script>


<link rel="shortcut icon" href="../_static/icon.ico" />


  </head>
  <body>
<div class="wrapper">
  <a href="../"><img src="../_static/banner.png" width="900px" alt="dolfin-adjoint Project Banner" /></a>
  <div id="access">
    <div class="menu">
      <ul>
          <li class="page_item"><a href="../about/index.html" title="Find out more about dolfin-adjoint">About</a></li>
          <li class="page_item"><a href="../features/index.html" title="Features of dolfin-adjoint">Features</a></li>
          <li class="page_item"><a href="index.html" title="Learn how to use dolfin-adjoint">Documentation</a></li>
          <li class="page_item"><a href="../download/index.html" title="Obtain the dolfin-adjoint code">Download</a></li>
          <li class="page_item"><a href="../citing/index.html" title="Learn how to cite the dolfin-adjoint project">Citing</a></li>
          <li class="page_item"><a href="../support/index.html" title="Where to go for more help">Support</a></li>
      </ul>
    </div><!-- .menu -->
  </div><!-- #access -->
</div><!-- #wrapper -->


    <div class="document">
      <div class="documentwrapper">
        <div class="bodywrapper">
          <div class="body" role="main">
            
  <div class="section" id="pde-constrained-optimisation">
<h1>PDE-constrained optimisation<a class="headerlink" href="#pde-constrained-optimisation" title="Permalink to this headline">¶</a></h1>
<p>PDE-constrained optimisation problems are problems of the form:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\min_{u,m} J(u, m)\\\mathrm{subject~to}\\F(u, m) = 0\\l_u \le m \le l_b\\g(m) \le 0\end{aligned}\end{align} \]</div>
<p>where <span class="math">\(m\)</span> contains the optimisation variables, <span class="math">\(J\)</span> is a
real valued objective functional, <span class="math">\(F(u, m) = 0\)</span> is the PDE with
solution <span class="math">\(u\)</span>.  The bounds and inequality constraints can be used
to restrict the feasible optimisation variables.</p>
<p>For an introduction to the mathematics, see <a class="reference internal" href="maths/2-problem.html"><span class="doc">the chapter in the
mathematical background</span></a>.</p>
<div class="section" id="the-reduced-functional">
<h2>The reduced functional<a class="headerlink" href="#the-reduced-functional" title="Permalink to this headline">¶</a></h2>
<p>While it is possible to solve the optimisation problem above directly,
we often prefer to form the so-called <cite>reduced problem</cite>.  Given that
for every <span class="math">\(m\)</span> the PDE yields a unique solution <span class="math">\(u\)</span>, we can
define a solution operator <span class="math">\(u(m)\)</span>.  Substituting this operator
into the optimisation problem yields the reduced problem:</p>
<div class="math">
\[ \begin{align}\begin{aligned}\min_{m} J(u(m), m)\\\mathrm{subject~to}\\l_u \le m \le l_b\\g(m) \le 0\end{aligned}\end{align} \]</div>
<p>The advantage of solving this formulation is that the PDE-constraint
is exactly satisfied at each optimisation iteration.  In particular,
the optimisation loop can be terminated as soon as the functional is
sufficiently reduced by the optimisation algorithm, without any
feasibility iterations.</p>
<p>The functional in the reduced form can be seen as a function that only
depends on the optimisation variable <cite>m</cite>, that is:</p>
<div class="math">
\[\tilde J(m) := J(u(m), m)\]</div>
<p>The definition of this <cite>reduced functional</cite> <span class="math">\(\tilde J\)</span> is the
first step of solving an optimisation problem with dolfin-adjoint.  It
is created with:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<p>where <code class="xref py py-data docutils literal"><span class="pre">J</span></code> is a <code class="xref py py-class docutils literal"><span class="pre">Functional</span></code> and <code class="xref py py-data docutils literal"><span class="pre">m</span></code> is a
<code class="xref py py-class docutils literal"><span class="pre">Control</span></code> (e.g. a
<code class="xref py py-class docutils literal"><span class="pre">ConstantControl</span></code> or <code class="xref py py-class docutils literal"><span class="pre">FunctionControl</span></code>).</p>
<p><em>Important</em>: <code class="xref py py-class docutils literal"><span class="pre">ReducedFunctional</span></code> works by replaying the
simulation record of <cite>dolfin-adjoint</cite>. Therefore, make sure that you
execute the forward model once before using it.</p>
</div>
<div class="section" id="solving-the-optimisation-problem">
<h2>Solving the optimisation problem<a class="headerlink" href="#solving-the-optimisation-problem" title="Permalink to this headline">¶</a></h2>
<p>Once the reduced functional is defined, we are only one step away from
solving the optimisation problem:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">)</span>
</pre></div>
</div>
<p>or if a maximization problem is to be solved:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">m_opt</span> <span class="o">=</span> <span class="n">maximize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, the optimisation problem is solved using limited memory
BFGS method with bound support.</p>
</div>
<div class="section" id="features">
<h2>Features<a class="headerlink" href="#features" title="Permalink to this headline">¶</a></h2>
<p><em>Important: Please make sure that you have scipy &gt;= 0.11 installed.
Older scipy versions are only partly supported and require different
arguments. You can check your scipy version with</em></p>
<div class="highlight-python"><div class="highlight"><pre><span class="kn">import</span> <span class="nn">scipy</span>
<span class="k">print</span> <span class="n">scipy</span><span class="o">.</span><span class="n">__version__</span>
</pre></div>
</div>
<div class="section" id="choosing-the-optimisation-algorithm">
<h3>Choosing the optimisation algorithm<a class="headerlink" href="#choosing-the-optimisation-algorithm" title="Permalink to this headline">¶</a></h3>
<p>The optimisation module currently supports following optimisation
algorithms:</p>
<ul class="simple">
<li><em>CG</em>:  The nonlinear conjugate gradient algorithm.</li>
<li><em>BFGS</em>:  The Broyden–Fletcher–Goldfarb–Shanno (BFGS) method.</li>
<li><em>L-BFGS-B</em>:  A limited memory BFGS implementation with bound support.</li>
<li><em>SLSQP</em>:  The sequential least squares quadratic programming algorithm.</li>
<li><em>TNC</em>:  The truncated Newton algorithm with bound support.</li>
<li><em>Nelder-Mead</em>:  The Simplex algorithm (gradient-free).</li>
<li><em>Newton-CG</em>:  The truncated Newton algorithm.</li>
<li><em>Anneal</em>:  The simulated annealing method (gradient-free).</li>
<li><em>COBYLA</em>: Constrained optimization by linear approximation.</li>
<li><em>Powell</em>: The Powell’s method (gradient-free).</li>
</ul>
<p>More details about the algorithms can be found on the <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html#scipy.optimize.minimize">scipy.optimize</a>
web page.</p>
<p>This list can be generated by calling:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">print_optimization_methods</span><span class="p">()</span>
</pre></div>
</div>
<p>By default, the framework uses the <em>L-BFGS-B</em> method.  A different
algorithm can be selected by adding the <cite>method</cite> argument to
<cite>minimize</cite> or <cite>maximize</cite> and providing one of the names from the list
above, e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="callbacks">
<h3>Callbacks<a class="headerlink" href="#callbacks" title="Permalink to this headline">¶</a></h3>
<p>Often one wants to add a callback function that is executed after
every optimisation iteration, for example to save or plot the
functional or parameter values.  The optimisation framework provides
two ways how this can be achieved.</p>
<div class="section" id="option-1">
<h4>Option 1<a class="headerlink" href="#option-1" title="Permalink to this headline">¶</a></h4>
<p>One can attach callbacks functions to <code class="xref py py-class docutils literal"><span class="pre">ReducedFunctional</span></code>
object which are executed whenever the functional is evaluated.  There
are separate callbacks for functional evaluation and functional
gradient evaluation.</p>
<p>The following code example prints the functional value, functional
gradient and the associated scalar parameter:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">eval_cb</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
  <span class="k">print</span> <span class="s2">&quot;j = </span><span class="si">%f</span><span class="s2">, m = </span><span class="si">%f</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">derivative_cb</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">dj</span><span class="p">,</span> <span class="n">m</span><span class="p">):</span>
  <span class="k">print</span> <span class="s2">&quot;j = </span><span class="si">%f</span><span class="s2">, dj = </span><span class="si">%f</span><span class="s2">, m = </span><span class="si">%f</span><span class="s2">.&quot;</span> <span class="o">%</span> <span class="p">(</span><span class="n">j</span><span class="p">,</span> <span class="n">dj</span><span class="p">,</span> <span class="nb">float</span><span class="p">(</span><span class="n">m</span><span class="p">))</span>

<span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">ConstantControl</span><span class="p">(</span><span class="s2">&quot;Nu&quot;</span><span class="p">),</span>
                                       <span class="n">eval_cb</span> <span class="o">=</span> <span class="n">eval_cb</span><span class="p">,</span>
                                       <span class="n">derivative_cb</span> <span class="o">=</span> <span class="n">derivative_cb</span><span class="p">)</span>
</pre></div>
</div>
<p>In most gradient-based optimisation methods, the gradient is evaluated
at the beginning of a new optimisation iteration.  Hence, if one wants
to plot the progress of the optimisation, the derivative callback is
the natural choice.</p>
</div>
<div class="section" id="option-2">
<h4>Option 2<a class="headerlink" href="#option-2" title="Permalink to this headline">¶</a></h4>
<p>Alternatively, one can attach a callback function to the minimize (or
maximize) routine (see below). However, this callback takes only the
parameter value as an argument and therefore this method is not
suitable if one wants to plot the functional values during the
optimisation.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="k">def</span> <span class="nf">iter_cb</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>
  <span class="k">print</span> <span class="s2">&quot;m = &quot;</span><span class="p">,</span> <span class="n">m</span>

<span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">callback</span> <span class="o">=</span> <span class="n">iter_cb</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="advanced-optimisation-options">
<h3>Advanced optimisation options<a class="headerlink" href="#advanced-optimisation-options" title="Permalink to this headline">¶</a></h3>
<p>Each optimisation algorithm supports different features and hence has
different configuration options.  To be able to access these options,
any arguments that are unknown to <cite>minimize</cite> or <cite>maximize</cite> will be
passed to the optimisation algorithm.</p>
<p>The most relevant options that can be used with all supported
optimisation methods are:</p>
<ul class="simple">
<li><em>tol</em>: Tolerance for termination. For detailed control, use solver-specific options.</li>
<li><em>options</em>: A dictionary of solver options. All methods accept the following generic options:<ul>
<li><em>maxiter</em>: Maximum number of iterations to perform.</li>
<li><em>disp</em>: Set to True to print convergence messages.</li>
<li><em>gtol</em>: The iteration loops stops if the gradient norm drops below this tolerance.</li>
</ul>
</li>
</ul>
<p><img alt="more info" class="align-middle" src="../_images/more.png" /> For method-specific options, see scipy’s function
<em>show_options(‘minimize’, method)</em>.</p>
<p>For example:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s1">&#39;SLSQP&#39;</span><span class="p">,</span> <span class="n">tol</span> <span class="o">=</span> <span class="mf">1e-10</span><span class="p">,</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;disp&#39;</span><span class="p">:</span> <span class="bp">True</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="section" id="multiple-parameters">
<h3>Multiple parameters<a class="headerlink" href="#multiple-parameters" title="Permalink to this headline">¶</a></h3>
<p>The optimisation module can handle multiple optimisation parameters.
Simply pass a list of parameters to <code class="xref py py-data docutils literal"><span class="pre">ReducedFunctional</span></code>:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="p">[</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
<span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="bounds">
<h3>Bounds<a class="headerlink" href="#bounds" title="Permalink to this headline">¶</a></h3>
<p>If the optimisation algorithm supports bounds of the form <span class="math">\(b_u &lt;
m &lt; b_u\)</span> this functionality can be used by adding the <cite>bounds</cite>
argument to <cite>minimize</cite> or <cite>maximize</cite>.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">bounds</span> <span class="o">=</span> <span class="p">(</span><span class="n">m_lb</span><span class="p">,</span> <span class="n">m_ub</span><span class="p">))</span>
</pre></div>
</div>
<p>where <cite>m_lb</cite> and <cite>m_ub</cite> are objects of the same type than the
parameter that contain the lower and the upper bound values.</p>
<p>If the bounds are constants, a set of floats can be passed
alternatively, e.g.:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">m</span><span class="p">)</span>
<span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">bounds</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">))</span>
</pre></div>
</div>
<p>In the case where multiple parameters are optimised, the bound
parameter must consist of a list whose elements contains the bounds
for each parameter, i.e.</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="p">[</span><span class="n">m1</span><span class="p">,</span> <span class="n">m2</span><span class="p">,</span> <span class="o">...</span><span class="p">])</span>
<span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">bounds</span> <span class="o">=</span> <span class="p">[(</span><span class="n">m1_lb</span><span class="p">,</span> <span class="n">m1_ub</span><span class="p">),</span> <span class="p">(</span><span class="n">m2_lb</span><span class="p">,</span> <span class="n">m2_ub</span><span class="p">),</span> <span class="o">...</span><span class="p">])</span>
</pre></div>
</div>
<p>where each of the <cite>m1_lb</cite>, <cite>m1_ub</cite>, <cite>m2_lb</cite>, … are objects of the
same type as the parameter.</p>
</div>
<div class="section" id="debugging">
<h3>Debugging<a class="headerlink" href="#debugging" title="Permalink to this headline">¶</a></h3>
<p>Sometimes, the optimisation algorithm does not converge or terminates
with an error that indicates that the gradient might be incorrect.  In
theses cases, it is a good idea to make sure that the gradient
evaluation is indeed correct.  This is achieved by running the
<a class="reference internal" href="verification.html"><span class="doc">Taylor test</span></a> for every gradient evaluation that
occurs during the optimisation.  This functionality is activated with:</p>
<div class="highlight-python"><div class="highlight"><pre><span class="n">dolfin</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;optimization&quot;</span><span class="p">][</span><span class="s2">&quot;test_gradient&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="bp">True</span>
<span class="n">dolfin</span><span class="o">.</span><span class="n">parameters</span><span class="p">[</span><span class="s2">&quot;optimization&quot;</span><span class="p">][</span><span class="s2">&quot;test_gradient_seed&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.0001</span>
</pre></div>
</div>
<p>By default, the gradient test is deactivated. If no <cite>gradient_seed</cite> is
specified the value <cite>0.0001</cite> is used.</p>
</div>
</div>
<div class="section" id="example">
<h2>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h2>
<p>The following example shows the code for solving the optimal control
of the heat equation:</p>
<div class="highlight-default"><div class="highlight"><pre><span class="sd">&quot;&quot;&quot; Solves the optimal control problem for the heat equation &quot;&quot;&quot;</span>
<span class="kn">from</span> <span class="nn">dolfin</span> <span class="k">import</span> <span class="o">*</span>
<span class="kn">from</span> <span class="nn">dolfin_adjoint</span> <span class="k">import</span> <span class="o">*</span>

<span class="c1"># Setup</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">mesh</span> <span class="o">=</span> <span class="n">RectangleMesh</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span><span class="p">,</span> <span class="n">n</span><span class="p">)</span>
<span class="n">V</span> <span class="o">=</span> <span class="n">FunctionSpace</span><span class="p">(</span><span class="n">mesh</span><span class="p">,</span> <span class="s2">&quot;CG&quot;</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">Function</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;State&quot;</span><span class="p">)</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">Function</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s2">&quot;Control&quot;</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">TestFunction</span><span class="p">(</span><span class="n">V</span><span class="p">)</span>

<span class="c1"># Run the forward model once to create the simulation record</span>
<span class="n">F</span> <span class="o">=</span> <span class="p">(</span><span class="n">inner</span><span class="p">(</span><span class="n">grad</span><span class="p">(</span><span class="n">u</span><span class="p">),</span> <span class="n">grad</span><span class="p">(</span><span class="n">v</span><span class="p">))</span> <span class="o">-</span> <span class="n">m</span><span class="o">*</span><span class="n">v</span><span class="p">)</span><span class="o">*</span><span class="n">dx</span>
<span class="n">bc</span> <span class="o">=</span> <span class="n">DirichletBC</span><span class="p">(</span><span class="n">V</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="s2">&quot;on_boundary&quot;</span><span class="p">)</span>
<span class="n">solve</span><span class="p">(</span><span class="n">F</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="n">u</span><span class="p">,</span> <span class="n">bc</span><span class="p">)</span>

<span class="c1"># The functional of interest is the normed difference between desired</span>
<span class="c1"># and simulated temperature profile</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">triangle</span><span class="o">.</span><span class="n">x</span>
<span class="n">u_desired</span> <span class="o">=</span> <span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">-</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">*</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]))</span>
<span class="n">J</span> <span class="o">=</span> <span class="n">Functional</span><span class="p">((</span><span class="mf">0.5</span><span class="o">*</span><span class="n">inner</span><span class="p">(</span><span class="n">u</span><span class="o">-</span><span class="n">u_desired</span><span class="p">,</span> <span class="n">u</span><span class="o">-</span><span class="n">u_desired</span><span class="p">))</span><span class="o">*</span><span class="n">dx</span><span class="o">*</span><span class="n">dt</span><span class="p">[</span><span class="n">FINISH_TIME</span><span class="p">])</span>

<span class="c1"># Run the optimisation</span>
<span class="n">reduced_functional</span> <span class="o">=</span> <span class="n">ReducedFunctional</span><span class="p">(</span><span class="n">J</span><span class="p">,</span> <span class="n">Control</span><span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">value</span><span class="o">=</span><span class="n">m</span><span class="p">))</span>
<span class="c1"># Make sure you have scipy &gt;= 0.11 installed</span>
<span class="n">m_opt</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">reduced_functional</span><span class="p">,</span> <span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;L-BFGS-B&quot;</span><span class="p">,</span>
                 <span class="n">tol</span><span class="o">=</span><span class="mi">2</span><span class="n">e</span><span class="o">-</span><span class="mi">08</span><span class="p">,</span> <span class="n">bounds</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="n">options</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;disp&quot;</span><span class="p">:</span> <span class="kc">True</span><span class="p">})</span>
</pre></div>
</div>
<p><img alt="more info" class="align-middle" src="../_images/more.png" /> Download the <a class="reference external" href="../_static/optimal_control.py">optimisation code</a>.</p>
<p>This prints the following output that contains various information,
such as the final functional value:</p>
<div class="highlight-none"><div class="highlight"><pre>$ python optimal_control.py
...
N   Tit  Tnf  Tnint  Skip  Nact     Projg        F
40401    6    8      6     0     0   8.153D-09   1.809D-05
F =  1.80922786897687845E-005

CONVERGENCE: NORM OF PROJECTED GRADIENT &lt;= PGTOL
</pre></div>
</div>
</div>
</div>


          </div>
        </div>
      </div>
      <div class="clearer"></div>
    </div>
    <div class="footer" role="contentinfo">
        &#169; Copyright 2017, Sebastian Mitusch.
      Created using <a href="http://sphinx-doc.org/">Sphinx</a> 1.6.2.
    </div>
  </body>
</html>